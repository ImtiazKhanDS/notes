---
share: true
---
1. Watched video by Andrew karpathy  
2. Watch video by Jeremy howard  
3. Explore langchain   
4. Explore Cody neovim  
5. Explore llama2  
6. Explore mixtral  
7. Explore mamba architecture  
8. Explore Rag based approaches  
9. Search  
10. Ranking  
11. Personalisation of search results.  
  
Kaggle's LLM Science Exam competition [https://lnkd.in/gvrFhfR8](https://lnkd.in/gvrFhfR8) made participants answer hard science questions. The winning solution showed Llama-2 70b with prompting gets 80%. + finetuning via SFT you get 86%. But + finetuning + RAG you get 93%. All had to undergo finetuning since the output was MMLU's classification type ie output A, B, C, D etc (so a classification problem).  
  
1. Together.ai all models in one place  
2. Colm website for research ideas